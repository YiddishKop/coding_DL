說明：請各位使用此template進行Report撰寫，如果想要用其他排版模式也請註明題號以及
題目內容（請勿擅自更改題號），最後上傳至github前，請務必轉成PDF檔，並且命名為
report.pdf，否則將不予計分。

----------------------------------------閱讀完以上文字請刪除------------------------------------

學號：B02123456  系級： 電機四  姓名：法拉利

請實做以下兩種不同feature的模型，回答第 (1) ~ (3) 題：
1. 抽全部9小時內的污染源feature的一次項(加bias)
2. 抽全部9小時內pm2.5的一次項當作feature(加bias)


備註 :
      1. NR請皆設為0，其他的數值不要做任何更動
      2. 所有 advanced 的 gradient descent 技術(如: adam, adagrad 等) 都是可以用的

1. (2%)記錄誤差值 (RMSE)(根據kaggle public+private分數)，討論兩種feature的影響

2. (1%)將feature從抽前9小時改成抽前5小時，討論其變化

3. (1%)Regularization on all the weight with λ=0.1、0.01、0.001、0.0001，並作圖

4. (1%)在線性回歸問題中，假設有 N 筆訓練資料，每筆訓練資料的特徵 (feature) 為一
   向量 $x_n$，其標註(label)為一存量 $y_n$ ，模型參數為一向量w (此處忽略偏權值
   b)，則線性回歸的損失函數(loss function)為 $\sum_{n=1}^N{(y_n -
   (x_n\cdot{w}))^2}$ 。若將所有訓練資料的特徵值以矩陣 $X = [x_1 x_2 … x_N]^T$
   表示，所有訓練資料的標註以向量 $y = [y_1 y_2 … y_N]^T$ 表示，請問如何以 X 和
   y 表示可以最小化損失函數的向量 w ？請寫下算式並選出正確答案。(其中 $X^TX$ 為
   invertible)

(XTX)XTy
(XTX)-0XTy
(XTX)-1XTy <-
(XTX)-2XTy
